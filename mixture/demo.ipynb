{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import decord\n",
    "from decord import VideoReader\n",
    "from decord import cpu, gpu\n",
    "decord.bridge.set_bridge('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/e/workplace/hackathons/27-09-tagging-video/archive/MA-LMM-main/mixture\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "VIDEO_DIR = Path(os.getcwd()).parent / \"example\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame mixture function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_mixer(\n",
    "        vr : VideoReader, start_time=0, end_time=None,\n",
    "        threshold=120, frame_limit=100, step_frames=5\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Смешивает кадры видео, используя заданный порог различия и лимит кадров.\n",
    "\n",
    "    Аргументы:\n",
    "        vr (VideoReader): Объект чтения видео.\n",
    "        start_time (int, optional): Начальное время в секундах. Defaults to 0.\n",
    "        end_time (int, optional): Конечное время в секундах. Defaults to None.\n",
    "        threshold (int, optional): Порог различия между кадрами. Defaults to 120.\n",
    "        frame_limit (int, optional): Лимит кадров для смешивания. Defaults to 100.\n",
    "        step_frames (int, optional): Шаг кадров для чтения видео. Defaults to 5.\n",
    "\n",
    "    Yield:\n",
    "        tuple (numpy.ndarray, list): Смешанный кадр и средний идентификатор смешанных кадров.\n",
    "    \"\"\"\n",
    "    if end_time is None:\n",
    "        end_time = len(vr)\n",
    "\n",
    "    frame_id_list = range(start_time, end_time, step_frames)\n",
    "    mixed_frame, frame_iter = None, 0\n",
    "    ids_mixes_list = []\n",
    "    id_begin, id_end = None, None\n",
    "    batch = vr.get_batch(frame_id_list)\n",
    "    for i, frame in enumerate(batch):\n",
    "        frame = frame.numpy()\n",
    "        if mixed_frame is None:\n",
    "            mixed_frame, frame_iter = frame, 1\n",
    "            id_begin = i * step_frames\n",
    "            continue\n",
    "        if frame_iter >= frame_limit:\n",
    "            id_end = i * step_frames\n",
    "            mean_id_mix = (id_begin + id_end) // 2\n",
    "\n",
    "            yield mixed_frame, mean_id_mix\n",
    "            mixed_frame, frame_iter = frame, 1\n",
    "            id_begin = (i+1) * step_frames\n",
    "            continue\n",
    "\n",
    "        frame_iter += 1\n",
    "        # diff = abs(frame.numpy() - mixed_frame.numpy())\n",
    "        diff = abs(frame - mixed_frame)\n",
    "\n",
    "        if diff.mean() > threshold:\n",
    "            # yield torch.tensor(mixed_frame)\n",
    "            id_end = i * step_frames\n",
    "            mean_id_mix = (id_begin + id_end) // 2\n",
    "            yield mixed_frame, mean_id_mix\n",
    "            mixed_frame, frame_iter = frame, 1\n",
    "            id_begin = (i+1) * step_frames\n",
    "            continue\n",
    "\n",
    "        # mixed_frame = cv2.addWeighted(mixed_frame.numpy(), 0.5, frame.numpy(), 0.5, 0)\n",
    "        mixed_frame = cv2.addWeighted(mixed_frame, 0.5, frame, 0.5, 0)\n",
    "        # mixed_frame = torch.tensor(mixed_frame)\n",
    "    id_end = len(batch) * step_frames\n",
    "    mean_id_mix = (id_begin + id_end) // 2\n",
    "    yield mixed_frame, mean_id_mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(mix_list, start_time, end_time, fps) -> torch.Tensor:\n",
    "    return mix_list.permute(3, 0, 1, 2).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_duration: 70.3, fps: 24.0\n",
      "frames: 1687\n"
     ]
    }
   ],
   "source": [
    "file_path =  str(VIDEO_DIR / \"video.mp4\")\n",
    "vr = VideoReader(file_path, ctx=cpu(0), num_threads=4)\n",
    "total_frames = len(vr)\n",
    "fps = int(vr.get_avg_fps())\n",
    "duration = total_frames / fps\n",
    "print(\"video_duration: {:.1f}, fps: {:.1f}\".format(duration, fps))\n",
    "print(f\"frames: {total_frames}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th = 255/2\n",
    "sec = 10\n",
    "k = 3\n",
    "gen = video_mixer(vr,\n",
    "                threshold=th,\n",
    "                frame_limit=fps*sec,\n",
    "                step_frames=k,\n",
    "                )\n",
    "mix_lst, mean_id_mixes = zip(*gen)\n",
    "\n",
    "# k = 3\n",
    "# mix_lst = list(video_mixer(vr,\n",
    "#                            threshold=255/2,\n",
    "#                            frame_limit=k*int(fps),\n",
    "#                            step_frames=4,\n",
    "#                            ))\n",
    "len(mix_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55,\n",
       " 115,\n",
       " 121,\n",
       " 231,\n",
       " 529,\n",
       " 723,\n",
       " 727,\n",
       " 765,\n",
       " 801,\n",
       " 804,\n",
       " 807,\n",
       " 823,\n",
       " 862,\n",
       " 888,\n",
       " 891,\n",
       " 894,\n",
       " 897,\n",
       " 1003,\n",
       " 1117,\n",
       " 1246,\n",
       " 1423,\n",
       " 1524,\n",
       " 1570,\n",
       " 1632)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_id_mixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fps = 1.0\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "width, height = mix_lst[0].shape[1], mix_lst[0].shape[0]\n",
    "\n",
    "# Create a VideoWriter object\n",
    "video_writer = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# Iterate through the frames and write them to the video\n",
    "for frame in mix_lst:\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    video_writer.write(frame)\n",
    "\n",
    "# Release the VideoWriter object\n",
    "video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Size([3, frames_size=20, 360, 640])\n",
    "# video.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MA-LMM-main-7M0IOe3A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
